apiVersion: kubeaddons.mesosphere.io/v1beta1
kind: Addon
metadata:
  name: fluentbit
  namespace: kubeaddons
  labels:
    kubeaddons.mesosphere.io/name: fluentbit
  annotations:
    catalog.kubeaddons.mesosphere.io/addon-revision: "1.7.3-1"
    appversion.kubeaddons.mesosphere.io/fluentbit: "1.7.3"
    values.chart.helm.kubeaddons.mesosphere.io/fluentbit: "https://raw.githubusercontent.com/fluent/helm-charts/1c4d46b7bd15ead0f23d3c61183a1e3cda931da0/charts/fluent-bit/values.yaml"
    # the older versions were being deployed from stable/fluent-bit
    # and were versioned like 2.8.x
    helm.kubeaddons.mesosphere.io/upgrade-strategy: "[{\"upgradeFrom\": \">=2.8.0\", \"strategy\": \"delete\"}]"
    helm2.kubeaddons.mesosphere.io/upgrade-strategy: "[{\"upgradeFrom\": \">=2.8.0\", \"strategy\": \"delete\"}]"
spec:
  kubernetes:
    minSupportedVersion: v1.15.6
  cloudProvider:
    - name: aws
      enabled: true
    - name: azure
      enabled: true
    - name: gcp
      enabled: true
    - name: vsphere
      enabled: true
    - name: docker
      enabled: false
    - name: none
      enabled: true
  chartReference:
    chart: fluent-bit
    repo: https://fluent.github.io/helm-charts
    version: 0.15.4
    values: |
      service:
        labels:
          servicemonitor.kubeaddons.mesosphere.io/path: "api__v1__metrics__prometheus"
          servicemonitor.kubeaddons.mesosphere.io/port: "http"
          servicemonitor.kubeaddons.mesosphere.io/interval: "10s"
      serviceMonitor:
          # right now disabled, as we need another solution for proper dependency to prometheus-operator
          enabled: false
          interval: 10s
          scrapeTimeout: 10s
          selector:
            release: prometheus-kubeaddons
      tolerations:
      - operator: Exists
        effect: NoSchedule
      - operator: Exists
        effect: NoExecute
      - operator: Exists
        key: CriticalAddonsOnly
      resources:
        limits:
          memory: 750Mi
        requests:
          cpu: 350m
          memory: 350Mi
      priorityClassName: system-node-critical
      securityContext:
        privileged: true
      env:
      - name: FLUENT_BIT_NODE_NAME
        valueFrom:
          fieldRef:
            fieldPath: spec.nodeName
      extraVolumes:
      # we create this to have a persistent tail-db directory an all nodes
      # otherwise a restarted fluent-bit would rescrape all tails
      - name: tail-db
        hostPath:
          path: /var/log/tail-db
          type: DirectoryOrCreate
      # we create this to get rid of error messages that would appear on non control-plane nodes
      - name: kubernetes-audit
        hostPath:
          path: /var/log/kubernetes/audit
          type: DirectoryOrCreate
      # needed for kmsg input plugin
      - name: uptime
        hostPath:
          path: /proc/uptime
          type: File
      - name: kmsg
        hostPath:
          path: /dev/kmsg
          type: CharDevice
      extraVolumeMounts:
      - name: tail-db
        mountPath: /tail-db
      - name: kubernetes-audit
        mountPath: /var/log/kubernetes/audit
      - name: uptime
        mountPath: /proc/uptime
      - name: kmsg
        mountPath: /dev/kmsg
      config:
        ## https://docs.fluentbit.io/manual/service
        service: |
          [SERVICE]
              Flush 1
              Daemon Off
              Log_Level error
              Parsers_File parsers.conf
              Parsers_File custom_parsers.conf
              HTTP_Server On
              HTTP_Listen 0.0.0.0
              HTTP_Port 2020

        ## https://docs.fluentbit.io/manual/pipeline/inputs
        inputs: |
          [INPUT]
              Name tail
              Alias kubernetes_audit
              Path /var/log/kubernetes/audit/*.log
              Parser kubernetes-audit
              DB /tail-db/audit.db
              Tag audit.*
              Refresh_Interval 10
              Rotate_Wait 5
              Mem_Buf_Limit 135MB
              Buffer_Chunk_Size 5MB
              Buffer_Max_Size 20MB
              Skip_Long_Lines Off
          [INPUT]
              Name tail
              Alias kubernetes_cluster
              Path /var/log/containers/*.log
              Parser cri
              DB /tail-db/kube.db
              Tag kube.*
              Refresh_Interval 60
              Rotate_Wait 5
              Mem_Buf_Limit 5MB
              Skip_Long_Lines On
          [INPUT]
              Name systemd
              Alias kubernetes_host
              DB /tail-db/journal.db
              Tag host.*
              Max_Entries 1000
              Read_From_Tail On
              Strip_Underscores On
          [INPUT]
              Name kmsg
              Alias kubernetes_host_kernel
              Tag kernel

        ## https://docs.fluentbit.io/manual/pipeline/filters
        filters: |
          [FILTER]
              Name record_modifier
              Match audit.*
              Record host ${FLUENT_BIT_NODE_NAME}
          [FILTER]
              Name kubernetes
              Match kube.*
              Merge_Log On
              Merge_Log_Key log_processed
              Keep_Log Off
              K8S-Logging.Parser On
              K8S-Logging.Exclude On
          [FILTER]
              Name record_modifier
              Match kernel
              Record host ${FLUENT_BIT_NODE_NAME}
          # We are adding the following filters here to have the workaround for
          # labels kubernetes.label.app=foobar.
          # Elasticsearch cannot accept single strings and beneath its new objects,
          # so it will reject all new entries when there is any kubernetes.label.app=foobar
          # entry already present. So what we do is that we remap / modify the kubernetes.label.app
          # to be kubernetes.label.app.kubernetes.io/name.
          [FILTER]
              Name                nest
              Match               kube.*
              Operation           lift
              Nested_under        kubernetes
              Add_prefix          kubernetes_
          [FILTER]
              Name                nest
              Match               kube.*
              Operation           lift
              Nested_under        kubernetes_labels
              Add_prefix          kubernetes_labels_
          [FILTER]
              Name                modify
              Match               kube.*
              Hard_rename         kubernetes_labels_app kubernetes_labels_app.kubernetes.io/name
          [FILTER]
              Name                nest
              Match               kube.*
              Operation           nest
              Wildcard            kubernetes_labels_*
              Nest_under          kubernetes.labels
              Remove_prefix       kubernetes_labels_
          [FILTER]
              Name                nest
              Match               kube.*
              Operation           nest
              Wildcard            kubernetes_*
              Nest_under          kubernetes
              Remove_prefix       kubernetes_
          [FILTER]
              Name                modify
              Match               kube.*
              Remove_wildcard     kubernetes_

        ## https://docs.fluentbit.io/manual/pipeline/outputs
        outputs: |
          [OUTPUT]
              Name es
              Alias kubernetes_audit
              Match audit.*
              Host elasticsearch-kubeaddons-client.kubeaddons.svc.cluster.local.
              Port 9200
              Time_Key @ts
              Logstash_Format On
              Logstash_Prefix kubernetes_audit
              # A small fraction of audit logs will be rejected by Elasticsearch because values may have an inconsistent type.
              # We set a low retry limit here in order to prevent fluent-bit from backing up while it repeatedly retries flushing these logs.
              # See https://github.com/uken/fluent-plugin-elasticsearch#random-400---rejected-by-elasticsearch-is-occured-why.
              Retry_Limit 1
              Buffer_Size 512KB
              # Audit logs may include resource labels, which may include dots. We replace them with underscores to
              # prevent conflicts that will cause Elasticsearch to reject logs.
              Replace_Dots On
          [OUTPUT]
              Name es
              Alias kubernetes_cluster
              Match kube.*
              Host elasticsearch-kubeaddons-client.kubeaddons.svc.cluster.local.
              Port 9200
              Time_Key @ts
              Logstash_Format On
              Logstash_Prefix kubernetes_cluster
              Retry_Limit 10
              Buffer_Size 512KB
          [OUTPUT]
              Name es
              Alias kubernetes_host
              Match host.*
              Host elasticsearch-kubeaddons-client.kubeaddons.svc.cluster.local.
              Port 9200
              Time_Key @ts
              Logstash_Format On
              Logstash_Prefix kubernetes_host
              Retry_Limit 10
              Buffer_Size 512KB
          [OUTPUT]
              Name es
              Alias kubernetes_host_kernel
              Match kernel
              Host elasticsearch-kubeaddons-client.kubeaddons.svc.cluster.local.
              Port 9200
              Time_Key @ts
              Logstash_Format On
              Logstash_Prefix kubernetes_host_kernel
              Retry_Limit 10
              Buffer_Size 512KB

        ## https://docs.fluentbit.io/manual/pipeline/parsers
        customParsers: |
          [PARSER]
              Name kubernetes-audit
              Format json
              Time_Keep On
              Time_Key requestReceivedTimestamp
              Time_Format %Y-%m-%dT%H:%M:%S.%L

      testFramework:
        enabled: false
